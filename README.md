# Layoff-Data-Cleaning-Pipeline-Using-SQL-Server
This project demonstrates an end to end data cleaning process using SQL Server to prepare a layoff dataset for analysis. The dataset, imported from a CSV file, was systematically cleaned to ensure accuracy, consistency and completeness.


### Steps Performed:
1. Data Import: Imported layoff data from a CSV file into SQL Server.
2. Data Profiling: Fetched and anlyzed the data structure to understand its content and quality.
3. Duplicate Removal: Identified duplicates using SQL aggreagtions with GROUP BY and removed them to maintain data integrity.
4. Handling Nulls and Blanks:
   * Checked for missing values in critical columns.
   * Replaced nulls and blanks with appropriate average values for consistency.

### Tools and Techniques Used:
* Database: SQL Server
* Techniques: Data Profling, Group By Aggregations, Null Handling
* Data Source: CSV file

#### Objective:
The Project showcases SQL techniques for cleaning and preparing datasets, ensuring data accuracy and integrity for downstream analytics and reporting.
